{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n",
      "Found 75 images belonging to 5 classes.\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 10s - loss: 5.3661 - acc: 0.2000 - val_loss: 1.6211 - val_acc: 0.0143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120893a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 384, 286\n",
    "\n",
    "train_data_dir = 'dataset_small/train'\n",
    "validation_data_dir = 'dataset_small/val'\n",
    "\n",
    "num_classes = 5\n",
    "# number of training examples (including all the classes)\n",
    "nb_train_samples = 10*5 #3042*5\n",
    "nb_validation_samples = 15*5\n",
    "epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('2_classification_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# done saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exporting the model to .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n",
    "config = model.get_config()\n",
    "weights = model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_config\n",
    "# new_model = model_from_config(config)\n",
    "new_model = Sequential.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "\n",
    "new_model.save('2_classification_new_dataset_test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddkuma/anaconda/lib/python2.7/site-packages/keras/models.py:245: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output nodes names are: ', ['output_node0'])\n",
      "('saved the graph definition in ascii format at: ', './export_2_classification/only_the_graph_def.pb.ascii')\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "('saved the constant graph (ready for inference) at: ', './export_2_classification/constant_graph_weights_new_dataset.pb')\n",
      "conv2d_1_input_2\n",
      "conv2d_1_2/kernel\n",
      "conv2d_1_2/kernel/read\n",
      "conv2d_1_2/bias\n",
      "conv2d_1_2/bias/read\n",
      "conv2d_1_2/convolution\n",
      "conv2d_1_2/BiasAdd\n",
      "activation_1_2/Relu\n",
      "max_pooling2d_1_2/MaxPool\n",
      "conv2d_2_2/kernel\n",
      "conv2d_2_2/kernel/read\n",
      "conv2d_2_2/bias\n",
      "conv2d_2_2/bias/read\n",
      "conv2d_2_2/convolution\n",
      "conv2d_2_2/BiasAdd\n",
      "activation_2_2/Relu\n",
      "max_pooling2d_2_2/MaxPool\n",
      "conv2d_3_2/kernel\n",
      "conv2d_3_2/kernel/read\n",
      "conv2d_3_2/bias\n",
      "conv2d_3_2/bias/read\n",
      "conv2d_3_2/convolution\n",
      "conv2d_3_2/BiasAdd\n",
      "activation_3_2/Relu\n",
      "max_pooling2d_3_2/MaxPool\n",
      "flatten_1_2/Shape\n",
      "flatten_1_2/strided_slice/stack\n",
      "flatten_1_2/strided_slice/stack_1\n",
      "flatten_1_2/strided_slice/stack_2\n",
      "flatten_1_2/strided_slice\n",
      "flatten_1_2/Const\n",
      "flatten_1_2/Prod\n",
      "flatten_1_2/stack/0\n",
      "flatten_1_2/stack\n",
      "flatten_1_2/Reshape\n",
      "dense_1_2/kernel\n",
      "dense_1_2/kernel/read\n",
      "dense_1_2/bias\n",
      "dense_1_2/bias/read\n",
      "dense_1_2/MatMul\n",
      "dense_1_2/BiasAdd\n",
      "activation_4_2/Relu\n",
      "dropout_1_2/Identity\n",
      "dense_2_2/kernel\n",
      "dense_2_2/kernel/read\n",
      "dense_2_2/bias\n",
      "dense_2_2/bias/read\n",
      "dense_2_2/MatMul\n",
      "dense_2_2/BiasAdd\n",
      "activation_5_2/Sigmoid\n",
      "output_node0\n"
     ]
    }
   ],
   "source": [
    "# model export starts here\n",
    "\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import os.path as osp\n",
    "from keras import backend as K\n",
    "\n",
    "weight_file_path = './2_classification_new_dataset_test_model.h5'\n",
    "num_output = 1\n",
    "prefix_output_node_names_of_final_network = 'output_node'\n",
    "export_path =  './export_2_classification' # where to save the exported graph\n",
    "output_graph_name = 'constant_graph_weights_new_dataset.pb'\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "pred = [None]*num_output\n",
    "pred_node_names = [None]*num_output\n",
    "net_model = load_model(weight_file_path)\n",
    "for i in range(num_output):\n",
    "    pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)\n",
    "    pred[i] = tf.identity(net_model.output, name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "\n",
    "\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "if 1:\n",
    "    f = 'only_the_graph_def.pb.ascii'\n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), export_path, f, as_text=True)\n",
    "    print('saved the graph definition in ascii format at: ', osp.join(export_path, f))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "graph_io.write_graph(constant_graph, export_path, output_graph_name, as_text=False)\n",
    "print('saved the constant graph (ready for inference) at: ', osp.join(export_path, output_graph_name))\n",
    "\n",
    "\n",
    "\n",
    "for n in constant_graph.node:\n",
    "    print(n.name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing and inference starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def, \n",
    "            input_map=None, \n",
    "            return_elements=None, \n",
    "            name=\"prefix\", \n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    return graph\n",
    "\n",
    "model = load_graph('./export_2_classification/constant_graph_weights_new_dataset.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix/conv2d_1_input_2\n",
      "prefix/conv2d_1_2/kernel\n",
      "prefix/conv2d_1_2/kernel/read\n",
      "prefix/conv2d_1_2/bias\n",
      "prefix/conv2d_1_2/bias/read\n",
      "prefix/conv2d_1_2/convolution\n",
      "prefix/conv2d_1_2/BiasAdd\n",
      "prefix/activation_1_2/Relu\n",
      "prefix/max_pooling2d_1_2/MaxPool\n",
      "prefix/conv2d_2_2/kernel\n",
      "prefix/conv2d_2_2/kernel/read\n",
      "prefix/conv2d_2_2/bias\n",
      "prefix/conv2d_2_2/bias/read\n",
      "prefix/conv2d_2_2/convolution\n",
      "prefix/conv2d_2_2/BiasAdd\n",
      "prefix/activation_2_2/Relu\n",
      "prefix/max_pooling2d_2_2/MaxPool\n",
      "prefix/conv2d_3_2/kernel\n",
      "prefix/conv2d_3_2/kernel/read\n",
      "prefix/conv2d_3_2/bias\n",
      "prefix/conv2d_3_2/bias/read\n",
      "prefix/conv2d_3_2/convolution\n",
      "prefix/conv2d_3_2/BiasAdd\n",
      "prefix/activation_3_2/Relu\n",
      "prefix/max_pooling2d_3_2/MaxPool\n",
      "prefix/flatten_1_2/Shape\n",
      "prefix/flatten_1_2/strided_slice/stack\n",
      "prefix/flatten_1_2/strided_slice/stack_1\n",
      "prefix/flatten_1_2/strided_slice/stack_2\n",
      "prefix/flatten_1_2/strided_slice\n",
      "prefix/flatten_1_2/Const\n",
      "prefix/flatten_1_2/Prod\n",
      "prefix/flatten_1_2/stack/0\n",
      "prefix/flatten_1_2/stack\n",
      "prefix/flatten_1_2/Reshape\n",
      "prefix/dense_1_2/kernel\n",
      "prefix/dense_1_2/kernel/read\n",
      "prefix/dense_1_2/bias\n",
      "prefix/dense_1_2/bias/read\n",
      "prefix/dense_1_2/MatMul\n",
      "prefix/dense_1_2/BiasAdd\n",
      "prefix/activation_4_2/Relu\n",
      "prefix/dropout_1_2/Identity\n",
      "prefix/dense_2_2/kernel\n",
      "prefix/dense_2_2/kernel/read\n",
      "prefix/dense_2_2/bias\n",
      "prefix/dense_2_2/bias/read\n",
      "prefix/dense_2_2/MatMul\n",
      "prefix/dense_2_2/BiasAdd\n",
      "prefix/activation_5_2/Sigmoid\n",
      "prefix/output_node0\n"
     ]
    }
   ],
   "source": [
    "for n in model.as_graph_def().node:\n",
    "    print n.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread('./dataset/val/WW/139.jpg')\n",
    "# img = np.reshape(img,[1,256,256,3])\n",
    "# img = img.astype(float)\n",
    "# img = img/255.0\n",
    "input_node = model.get_tensor_by_name(\"prefix/conv2d_1_input_2:0\")\n",
    "output_node = model.get_tensor_by_name(\"prefix/output_node0:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=model) as sess:\n",
    "        # Note: we didn't initialize/restore anything, everything is stored in the graph_def\n",
    "        y_out = sess.run(output_node, feed_dict={\n",
    "            input_node: img\n",
    "        })\n",
    "        print(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_data_dir = 'dataset/val'\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = new_model.predict_generator(generator=test_generator, steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WW/121.jpg', array([0]), array([ 0.00123855], dtype=float32))\n",
      "('WW/122.jpg', array([0]), array([  6.20405553e-05], dtype=float32))\n",
      "('WW/123.jpg', array([0]), array([ 0.2508404], dtype=float32))\n",
      "('WW/124.jpg', array([0]), array([ 0.00026049], dtype=float32))\n",
      "('WW/125.jpg', array([0]), array([  2.69901157e-05], dtype=float32))\n",
      "('WW/126.jpg', array([0]), array([ 0.00014258], dtype=float32))\n",
      "('WW/127.jpg', array([0]), array([ 0.0006878], dtype=float32))\n",
      "('WW/128.jpg', array([0]), array([ 0.0001845], dtype=float32))\n",
      "('WW/129.jpg', array([0]), array([  1.49825373e-05], dtype=float32))\n",
      "('WW/130.jpg', array([0]), array([  6.02863875e-05], dtype=float32))\n",
      "('WW/131.jpg', array([0]), array([ 0.00248698], dtype=float32))\n",
      "('WW/132.jpg', array([0]), array([ 0.00056203], dtype=float32))\n",
      "('WW/133.jpg', array([0]), array([  6.17742480e-05], dtype=float32))\n",
      "('WW/134.jpg', array([0]), array([ 0.00069535], dtype=float32))\n",
      "('WW/135.jpg', array([0]), array([ 0.00046818], dtype=float32))\n",
      "('WW/136.jpg', array([0]), array([  3.21307489e-05], dtype=float32))\n",
      "('WW/137.jpg', array([0]), array([  6.37230696e-05], dtype=float32))\n",
      "('WW/138.jpg', array([0]), array([  5.42188463e-05], dtype=float32))\n",
      "('WW/139.jpg', array([0]), array([ 0.00028595], dtype=float32))\n",
      "('WW/140.jpg', array([0]), array([ 0.00326181], dtype=float32))\n",
      "('WW/141.jpg', array([0]), array([ 0.00100297], dtype=float32))\n",
      "('WW/142.jpg', array([0]), array([ 0.00131795], dtype=float32))\n",
      "('WW/143.jpg', array([0]), array([ 0.03188691], dtype=float32))\n",
      "('WW/144.jpg', array([0]), array([  2.77524432e-05], dtype=float32))\n",
      "('WW/145.jpg', array([0]), array([ 0.00017819], dtype=float32))\n",
      "('WW/146.jpg', array([0]), array([ 0.0015573], dtype=float32))\n",
      "('WW/147.jpg', array([0]), array([ 0.00231848], dtype=float32))\n",
      "('WW/148.jpg', array([0]), array([ 0.00564443], dtype=float32))\n",
      "('WW/149.jpg', array([0]), array([ 0.00485792], dtype=float32))\n",
      "('WW/150.jpg', array([0]), array([  7.02585603e-05], dtype=float32))\n",
      "('regular/121.jpg', array([1]), array([ 0.99352431], dtype=float32))\n",
      "('regular/122.jpg', array([1]), array([ 0.99955398], dtype=float32))\n",
      "('regular/123.jpg', array([1]), array([ 0.99999988], dtype=float32))\n",
      "('regular/124.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/125.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/126.jpg', array([1]), array([ 0.99988568], dtype=float32))\n",
      "('regular/127.jpg', array([1]), array([ 0.98349667], dtype=float32))\n",
      "('regular/128.jpg', array([1]), array([ 0.9340266], dtype=float32))\n",
      "('regular/129.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/130.jpg', array([1]), array([ 0.99851161], dtype=float32))\n",
      "('regular/131.jpg', array([1]), array([ 0.99996161], dtype=float32))\n",
      "('regular/132.jpg', array([1]), array([ 0.99957651], dtype=float32))\n",
      "('regular/133.jpg', array([1]), array([ 0.99934119], dtype=float32))\n",
      "('regular/134.jpg', array([1]), array([ 0.99999988], dtype=float32))\n",
      "('regular/135.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/136.jpg', array([1]), array([ 0.9929564], dtype=float32))\n",
      "('regular/137.jpg', array([0]), array([ 0.23564239], dtype=float32))\n",
      "('regular/138.jpg', array([1]), array([ 0.86958176], dtype=float32))\n",
      "('regular/139.jpg', array([0]), array([ 0.0001535], dtype=float32))\n",
      "('regular/140.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/141.jpg', array([1]), array([ 0.95195711], dtype=float32))\n",
      "('regular/142.jpg', array([1]), array([ 0.9669736], dtype=float32))\n",
      "('regular/143.jpg', array([1]), array([ 0.9989785], dtype=float32))\n",
      "('regular/144.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/145.jpg', array([1]), array([ 0.99998415], dtype=float32))\n",
      "('regular/146.jpg', array([1]), array([ 0.99961877], dtype=float32))\n",
      "('regular/147.jpg', array([1]), array([ 0.86414188], dtype=float32))\n",
      "('regular/148.jpg', array([1]), array([ 1.], dtype=float32))\n",
      "('regular/149.jpg', array([0]), array([ 0.06643575], dtype=float32))\n",
      "('regular/150.jpg', array([1]), array([ 0.94808632], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "pred_cl = preds > 0.5\n",
    "pred_cl = pred_cl.astype(np.int)\n",
    "pred_for_file = zip(test_generator.filenames, pred_cl, preds)\n",
    "\n",
    "for i in pred_for_file:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
